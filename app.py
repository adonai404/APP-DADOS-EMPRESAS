import streamlit as st
import pdfplumber
import pandas as pd
import re
import os
from datetime import datetime
import openpyxl
from io import BytesIO
import logging

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

st.set_page_config(
    page_title="Extra√ß√£o de Dados Fiscais",
    page_icon="üè¢",
    layout="wide"
)

@st.cache_data
def limpar_valor_monetario(valor_str):
    """
    Converte valor monet√°rio do formato brasileiro para num√©rico
    Ex: "1.099,85" -> 1099.85
    """
    if not valor_str or valor_str == "N√£o encontrado":
        return 0.0
    
    # Remove R$ e espa√ßos
    valor_limpo = valor_str.replace('R$', '').replace(' ', '').strip()
    
    # Remove pontos (separador de milhar) e substitui v√≠rgula por ponto (decimal)
    valor_limpo = valor_limpo.replace('.', '').replace(',', '.')
    
    try:
        return float(valor_limpo)
    except:
        return 0.0

def normalizar_cnpj(cnpj):
    """
    Normaliza CNPJ removendo caracteres especiais e mantendo apenas n√∫meros
    """
    if not cnpj or cnpj == "N√£o encontrado" or pd.isna(cnpj):
        return ""
    return re.sub(r'[^\d]', '', str(cnpj))

def normalizar_nome_empresa(nome):
    """
    Normaliza nome da empresa para compara√ß√£o
    """
    if not nome:
        return ""
    return nome.upper().strip()

def consolidar_dados_empresa(dados_originais):
    """
    Consolida dados de ENTRADAS e PGDAS da mesma empresa e per√≠odo
    Usa l√≥gica melhorada baseada em agrupamento por empresa + per√≠odo
    """
    # Converter para DataFrame para facilitar o agrupamento
    df = pd.DataFrame(dados_originais)
    
    # Normalizar nome da empresa (remove espa√ßos extras, mai√∫sculas/min√∫sculas)
    df["Empresa_norm"] = df["Empresa"].str.strip().str.upper()
    
    # Criar chave de agrupamento apenas com Empresa + Per√≠odo
    # Usar per√≠odo de acordo com o tipo de documento
    df["periodo_consolidado"] = df.apply(lambda row: 
        row.get('Per√≠odo', '') if row.get('Tipo_Documento') == 'ENTRADAS' 
        else row.get('Per√≠odo de Apura√ß√£o', ''), axis=1)
    
    df["chave"] = df["Empresa_norm"] + "_" + df["periodo_consolidado"]
    
    # Mapear campos originais para os novos nomes
    # Criar colunas com os novos nomes baseados nos campos originais
    # Verificar se as colunas existem antes de acess√°-las
    df["entrada"] = df.get("Total de Entradas", None)
    df["sa√≠da"] = df.get("Receita Bruta Informada", None)
    df["imposto"] = df.get("Total do D√©bito Declarado", None)
    
    # Converter campos num√©ricos para float, tratando valores n√£o num√©ricos
    def converter_para_float(serie):
        """Converte s√©rie para float, tratando valores n√£o num√©ricos"""
        resultado = []
        for valor in serie:
            if pd.isna(valor) or valor == "N√£o encontrado" or valor is None:
                resultado.append(None)
            else:
                try:
                    # Se j√° √© num√©rico, mant√©m
                    if isinstance(valor, (int, float)):
                        resultado.append(float(valor))
                    else:
                        # Se √© string, tenta converter
                        resultado.append(limpar_valor_monetario(str(valor)))
                except:
                    resultado.append(None)
        return pd.Series(resultado)
    
    # Aplicar convers√£o para campos num√©ricos
    df["entrada"] = converter_para_float(df["entrada"])
    df["sa√≠da"] = converter_para_float(df["sa√≠da"])
    df["imposto"] = converter_para_float(df["imposto"])
    df["RBT12"] = converter_para_float(df.get("RBT12", None))
    
    # Consolida somando os valores num√©ricos
    df_final = df.groupby(["chave", "Empresa_norm", "periodo_consolidado"], as_index=False).agg({
        "CNPJ": lambda x: ', '.join(x.dropna().unique()) if x.dropna().any() else None,  # mant√©m todos CNPJs encontrados
        "entrada": lambda x: x.sum() if x.notna().any() else None,
        "RBT12": lambda x: x.sum() if x.notna().any() else None,
        "sa√≠da": lambda x: x.sum() if x.notna().any() else None,
        "imposto": lambda x: x.sum() if x.notna().any() else None
    })
    
    # Renomear colunas para o formato final
    df_final = df_final.rename(columns={
        "Empresa_norm": "Empresa",
        "periodo_consolidado": "Per√≠odo"
    })
    
    # Remover a coluna "chave" antes de retornar
    df_final = df_final.drop(columns=["chave"])
    
    # Adicionar coluna Situa√ß√£o vazia
    df_final["Situa√ß√£o"] = ""
    
    # Definir ordem das colunas
    ordem_colunas = [
        "Empresa",
        "CNPJ", 
        "Per√≠odo",
        "RBT12",
        "entrada",
        "sa√≠da",
        "imposto",
        "Situa√ß√£o"
    ]
    
    # Reordenar colunas
    df_final = df_final[ordem_colunas]
    
    # Converter de volta para lista de dicion√°rios
    dados_consolidados = df_final.to_dict('records')
    
    # Ordenar por empresa e per√≠odo
    dados_consolidados.sort(key=lambda x: (x['Empresa'], x['Per√≠odo']))
    
    return dados_consolidados

def detectar_tipo_documento(pdf_file):
    """
    Detecta automaticamente o tipo de documento baseado no conte√∫do do PDF
    Retorna: 'ENTRADAS', 'PGDAS' ou 'DESCONHECIDO'
    """
    try:
        with pdfplumber.open(pdf_file) as pdf:
            text = ""
            for page in pdf.pages:
                text += page.extract_text() + "\n"
        
        # Palavras-chave para identificar ENTRADAS
        palavras_entradas = [
            "Total de Entradas",
            "Relat√≥rio de Entradas",
            "Entradas do Per√≠odo"
        ]
        
        # Palavras-chave para identificar PGDAS
        palavras_pgdas = [
            "PGDAS",
            "Programa Gerador do DAS",
            "Per√≠odo de Apura√ß√£o (PA)",
            "Receita bruta acumulada nos doze meses anteriores ao PA",
            "Receita Bruta do PA (RPA) - Compet√™ncia",
            "Total Geral da Empresa",
            "IRPJ",
            "CSLL",
            "COFINS",
            "PIS/Pasep",
            "INSS/CPP",
            "ICMS",
            "IPI"
        ]
        
        # Contar ocorr√™ncias de palavras-chave
        contador_entradas = sum(1 for palavra in palavras_entradas if palavra.lower() in text.lower())
        contador_pgdas = sum(1 for palavra in palavras_pgdas if palavra.lower() in text.lower())
        
        # Determinar tipo baseado no maior n√∫mero de ocorr√™ncias
        if contador_entradas > contador_pgdas and contador_entradas > 0:
            return "ENTRADAS"
        elif contador_pgdas > contador_entradas and contador_pgdas > 0:
            return "PGDAS"
        else:
            # Se n√£o conseguir detectar claramente, tentar padr√µes mais espec√≠ficos
            if "Total de Entradas:" in text:
                return "ENTRADAS"
            elif "PGDAS" in text or "Programa Gerador do DAS" in text:
                return "PGDAS"
            else:
                return "DESCONHECIDO"
                
    except Exception as e:
        st.error(f"Erro ao detectar tipo do documento: {str(e)}")
        return "DESCONHECIDO"

def extrair_dados_entradas(pdf_file):
    """
    Extrai dados do PDF de relat√≥rios de entradas
    """
    data = {
        "Empresa": None,
        "CNPJ": None,
        "Per√≠odo": None,
        "Total de Entradas": None,
        "Tipo_Documento": "ENTRADAS"
    }

    with pdfplumber.open(pdf_file) as pdf:
        text = ""
        for page in pdf.pages:
            text += page.extract_text() + "\n"

    # Extrair nome da empresa
    empresa_match = re.search(r"([A-Z\s&]+LTDA)", text)
    if empresa_match:
        data["Empresa"] = empresa_match.group(1).strip()

    # Extrair CNPJ
    cnpj_match = re.search(r"CNPJ:\s*([\d./-]+)", text)
    if cnpj_match:
        data["CNPJ"] = cnpj_match.group(1).strip()

    # Extrair per√≠odo e simplificar para MM/AAAA
    periodo_match = re.search(r"Per√≠odo:\s*([\d/]+ at√© [\d/]+)", text)
    if periodo_match:
        periodo_completo = periodo_match.group(1).strip()
        # Extrair apenas o m√™s e ano do per√≠odo
        mes_ano_match = re.search(r"(\d{2})/(\d{4})", periodo_completo)
        if mes_ano_match:
            data["Per√≠odo"] = f"{mes_ano_match.group(1)}/{mes_ano_match.group(2)}"

    # Extrair apenas o total de entradas
    entradas_match = re.search(r"Total de Entradas:\s*([\d.,]+)", text)
    if entradas_match:
        data["Total de Entradas"] = float(entradas_match.group(1).replace(".", "").replace(",", "."))

    return data

def extrair_dados_pgdas(pdf_path):
    """
    Extrai dados do PDF do PGDAS
    """
    dados_por_arquivo = {
        'CNPJ': None,
        'Empresa': "N√£o encontrado",
        'Per√≠odo de Apura√ß√£o': "N√£o encontrado",
        'RBT12': "N√£o encontrado",
        'Receita Bruta Informada': "N√£o encontrado",
        'Total do D√©bito Declarado': "N√£o encontrado",
        'Tipo_Documento': "PGDAS"
    }
    
    try:
        with pdfplumber.open(pdf_path) as pdf:
            for pagina_num, pagina in enumerate(pdf.pages, 1):
                texto = pagina.extract_text()
                if texto:
                    lines = texto.split('\n')
                    
                    # Buscar RBT12
                    if dados_por_arquivo['RBT12'] == "N√£o encontrado":
                        for i, line in enumerate(lines):
                            if 'Receita bruta acumulada nos doze meses anteriores ao PA' in line and i + 1 < len(lines):
                                next_line = lines[i + 1].strip()
                                valor_match = re.search(r'([\d.,]+)', next_line)
                                if valor_match:
                                    dados_por_arquivo['RBT12'] = valor_match.group(1)
                                    break
                    
                    # Buscar Per√≠odo de Apura√ß√£o
                    if dados_por_arquivo['Per√≠odo de Apura√ß√£o'] == "N√£o encontrado":
                        pa_match = re.search(r'Per√≠odo de Apura√ß√£o \(PA\)[:\s]*(\d{2}/\d{4})', texto, re.IGNORECASE | re.MULTILINE)
                        if pa_match:
                            dados_por_arquivo['Per√≠odo de Apura√ß√£o'] = pa_match.group(1)
                    
                    # Buscar Receita Bruta Informada
                    if dados_por_arquivo['Receita Bruta Informada'] == "N√£o encontrado":
                        for line in lines:
                            if 'Receita Bruta do PA (RPA) - Compet√™ncia' in line:
                                valor_match = re.search(r'([\d.,]+)', line)
                                if valor_match:
                                    dados_por_arquivo['Receita Bruta Informada'] = valor_match.group(1)
                                    break
                    
                    # Buscar nome da empresa
                    if dados_por_arquivo['Empresa'] == "N√£o encontrado":
                        nome_match = re.search(r'Nome Empresarial[:\s]*([^,\n]+)', texto, re.IGNORECASE)
                        if nome_match:
                            dados_por_arquivo['Empresa'] = nome_match.group(1).strip()
                    
                    # Buscar Total do D√©bito Declarado
                    if dados_por_arquivo['Total do D√©bito Declarado'] == "N√£o encontrado":
                        for i, line in enumerate(lines):
                            if 'Total Geral da Empresa' in line:
                                for j in range(i+1, min(i+5, len(lines))):
                                    current_line = lines[j]
                                    if 'IRPJ' in current_line and 'CSLL' in current_line and 'COFINS' in current_line and 'Total' in current_line:
                                        if j + 1 < len(lines):
                                            valores_line = lines[j + 1]
                                            valores_match = re.findall(r'([\d.,]+)', valores_line)
                                            if valores_match:
                                                dados_por_arquivo['Total do D√©bito Declarado'] = valores_match[-1]
                                                break
                                break
                        
                        if dados_por_arquivo['Total do D√©bito Declarado'] == "N√£o encontrado":
                            for i, line in enumerate(lines):
                                valores_match = re.findall(r'([\d.,]+)', line)
                                if len(valores_match) >= 8:
                                    if i > 0 and 'IRPJ' in lines[i-1] and 'CSLL' in lines[i-1] and 'COFINS' in lines[i-1]:
                                        dados_por_arquivo['Total do D√©bito Declarado'] = valores_match[-1]
                                        break
                        
                        if dados_por_arquivo['Total do D√©bito Declarado'] == "N√£o encontrado":
                            for i, line in enumerate(lines):
                                if 'Total do D√©bito Declarado' in line and '(exig√≠vel + suspenso)' in line:
                                    for j in range(i+1, min(i+4, len(lines))):
                                        valores_line = lines[j]
                                        valores_match = re.findall(r'([\d.,]+)', valores_line)
                                        if len(valores_match) >= 8:
                                            dados_por_arquivo['Total do D√©bito Declarado'] = valores_match[-1]
                                            break
                                    break
    
    except Exception as e:
        st.error(f"Erro ao processar o PDF: {str(e)}")
        return []
    
    return [dados_por_arquivo] if any(valor != "N√£o encontrado" for valor in dados_por_arquivo.values()) else []

def main():
    st.title("Extra√ß√£o de Dados Fiscais")
    st.markdown("---")
    
    
    # # Informa√ß√µes sobre detec√ß√£o autom√°tica
    # st.info("ü§ñ **Detec√ß√£o Autom√°tica**: O sistema reconhece automaticamente se o PDF √© um relat√≥rio de Entradas ou documento PGDAS. Apenas fa√ßa upload dos arquivos!")
    
    # Upload √∫nico de arquivos
    st.subheader("üìÑ Upload de Arquivos")
    uploaded_files = st.file_uploader(
        "Selecione os arquivos PDFs",
        type="pdf",
        accept_multiple_files=True,
        help="Voc√™ pode misturar arquivos de Entradas e PGDAS. O sistema reconhecer√° cada um automaticamente."
    )
    
    if uploaded_files:
        # Processar arquivos com detec√ß√£o autom√°tica
        with st.spinner("Processando arquivos e detectando tipos automaticamente..."):
            todos_dados = []
            dados_por_empresa = {}
            tipos_detectados = {}
            
            # Barra de progresso
            progress_bar = st.progress(0)
            total_files = len(uploaded_files)
            
            for i, uploaded_file in enumerate(uploaded_files):
                # Atualizar barra de progresso
                progress_bar.progress((i + 1) / total_files)
                
                try:
                    # Salvar arquivo temporariamente
                    temp_path = f"temp_{uploaded_file.name}"
                    with open(temp_path, "wb") as f:
                        f.write(uploaded_file.getbuffer())
                    
                    # Detectar tipo do documento automaticamente
                    tipo_detectado = detectar_tipo_documento(temp_path)
                    tipos_detectados[uploaded_file.name] = tipo_detectado
                    
                    # Fallback para PGDAS se n√£o identificado
                    if tipo_detectado == "DESCONHECIDO":
                        tipo_detectado = "PGDAS"
                    
                    # Processar baseado no tipo detectado
                    if tipo_detectado == "ENTRADAS":
                        dados = extrair_dados_entradas(temp_path)
                        if dados and dados["Empresa"]:
                            todos_dados.append(dados)
                            
                            # Agrupar por empresa
                            empresa = dados["Empresa"]
                            if empresa not in dados_por_empresa:
                                dados_por_empresa[empresa] = {
                                    'dados_empresa': {
                                        'CNPJ': dados.get('CNPJ', 'N√£o encontrado'),
                                        'Nome_Empresa': empresa
                                    },
                                    'entradas': [],
                                    'pgdas': []
                                }
                            dados_por_empresa[empresa]['entradas'].append(dados)
                    
                    elif tipo_detectado == "PGDAS":
                        dados = extrair_dados_pgdas(temp_path)
                        for dado in dados:
                            if dado and dado["Empresa"]:
                                todos_dados.append(dado)
                                
                                # Agrupar por empresa
                                empresa = dado["Empresa"]
                                if empresa not in dados_por_empresa:
                                    dados_por_empresa[empresa] = {
                                        'dados_empresa': {
                                            'CNPJ': dado.get('CNPJ', 'N√£o encontrado'),
                                            'Nome_Empresa': empresa
                                        },
                                        'entradas': [],
                                        'pgdas': []
                                    }
                                dados_por_empresa[empresa]['pgdas'].append(dado)
                    
                except Exception as e:
                    st.error(f"Erro ao processar arquivo {uploaded_file.name}: {str(e)}")
                    logger.error(f"Erro ao processar {uploaded_file.name}: {str(e)}")
                
                finally:
                    # Limpar arquivo tempor√°rio
                    if os.path.exists(temp_path):
                        try:
                            os.remove(temp_path)
                        except:
                            pass
            
            # Limpar barra de progresso
            progress_bar.empty()
            
            # Mostrar resumo da detec√ß√£o
            st.markdown("### üìä Resumo da Detec√ß√£o Autom√°tica")
            col1, col2, col3 = st.columns(3)
            
            entradas_count = sum(1 for tipo in tipos_detectados.values() if tipo == "ENTRADAS")
            pgdas_count = sum(1 for tipo in tipos_detectados.values() if tipo == "PGDAS")
            desconhecidos_count = sum(1 for tipo in tipos_detectados.values() if tipo == "DESCONHECIDO")
            
            with col1:
                st.metric("üìä Relat√≥rios de Entradas", entradas_count)
            with col2:
                st.metric("üìã Documentos PGDAS", pgdas_count)
            with col3:
                st.metric("‚ùì N√£o Identificados", desconhecidos_count)
            
        if todos_dados:
            st.markdown("### üìä Dados Extra√≠dos")
            
            # Consolidar dados da mesma empresa e per√≠odo
            dados_consolidados = consolidar_dados_empresa(todos_dados)
            
            # Criar DataFrame unificado
            df_unificado = pd.DataFrame(dados_consolidados)
            
            # Mostrar informa√ß√µes sobre consolida√ß√£o
            st.info(f"üîÑ **Consolida√ß√£o Autom√°tica**: {len(todos_dados)} registros originais foram consolidados em {len(dados_consolidados)} registros √∫nicos por empresa/per√≠odo")
            
            # Filtros
            col1, col2, col3 = st.columns([2, 1, 1])
            
            with col1:
                busca_empresa = st.text_input("üîç Buscar empresa:", placeholder="Digite o nome da empresa...")
            
            with col2:
                filtro_dados = st.selectbox("üìÑ Dados:", ["Todos", "Com Entradas", "Com PGDAS", "Completos"])
            
            with col3:
                ordenacao = st.selectbox("üìä Ordenar por:", ["Empresa", "Per√≠odo", "Entrada", "Imposto"])
            
            # Aplicar filtros
            df_filtrado = df_unificado.copy()
            
            if busca_empresa:
                df_filtrado = df_filtrado[df_filtrado['Empresa'].str.contains(busca_empresa, case=False, na=False)]
            
            # Filtro por tipo de dados
            if filtro_dados == "Com Entradas":
                df_filtrado = df_filtrado[df_filtrado['entrada'].notna()]
            elif filtro_dados == "Com PGDAS":
                df_filtrado = df_filtrado[df_filtrado['RBT12'].notna()]
            elif filtro_dados == "Completos":
                df_filtrado = df_filtrado[
                    (df_filtrado['entrada'].notna()) & 
                    (df_filtrado['RBT12'].notna())
                ]
            
            # Ordena√ß√£o
            if ordenacao == "Empresa":
                df_filtrado = df_filtrado.sort_values('Empresa')
            elif ordenacao == "Per√≠odo":
                df_filtrado = df_filtrado.sort_values('Per√≠odo')
            elif ordenacao == "Entrada":
                df_filtrado = df_filtrado.sort_values('entrada', ascending=False, na_last=True)
            elif ordenacao == "Imposto":
                df_filtrado = df_filtrado.sort_values('imposto', ascending=False, na_last=True)
            
            # Exibir tabela
            st.dataframe(df_filtrado, use_container_width=True)
            
            # Estat√≠sticas
            st.info(f"üìà Exibindo {len(df_filtrado)} de {len(df_unificado)} registros")
            
            
            # Download Excel
            st.markdown("### üì• Exporta√ß√£o")
            
            output = BytesIO()
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                # Planilha principal
                df_unificado.to_excel(writer, sheet_name='Dados Consolidados', index=False)
            
            output.seek(0)
            
            st.download_button(
                label="üì• Download Excel Completo",
                data=output.getvalue(),
                file_name=f"Dados_Consolidados_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
        
        else:
            st.warning("Nenhum dado foi encontrado nos PDFs. Verifique se os arquivos cont√™m as informa√ß√µes esperadas.")

if __name__ == "__main__":
    main()